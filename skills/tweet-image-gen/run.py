#!/usr/bin/env python3
"""
TweetImageGen â€” æ¨æ–‡é…å›¾ç”Ÿæˆå™¨
æ ¹æ®æ¨æ–‡å†…å®¹å’Œé£æ ¼è‡ªåŠ¨ç”Ÿæˆé…å›¾

ç”¨æ³•:
    # å•æ¨æ–‡æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
    python run.py --tweet "æ¨æ–‡å†…å®¹" --style crypto --output ./output.png
    python run.py --tweet "æ¯”ç‰¹å¸çªç ´10ä¸‡ç¾å…ƒï¼" --style crypto
    
    # Thread/æ–‡ç« å¤šå›¾æ¨¡å¼
    python run.py --mode thread --tweet "æ®µè½1\n\næ®µè½2\n\næ®µè½3" --style crypto
    
    # ä»æ–‡ä»¶è¯»å–é•¿æ–‡æœ¬
    python run.py --mode thread --tweet-file ./article.txt --style news

é£æ ¼é€‰é¡¹:
    crypto   - åŠ å¯†è´§å¸/ç§‘æŠ€æ„Ÿ (é»˜è®¤)
    minimal  - æç®€ç™½åº•é£æ ¼
    news     - æ–°é—»æ„Ÿ/ä¿¡æ¯å›¾é£æ ¼
"""
import argparse
import os
import re
import sys
import time
import urllib.request
from typing import Optional, List

import fal_client
from openai import OpenAI

# FAL API Key
FAL_KEY = os.environ.get(
    "FAL_API_KEY",
    "6bfc9d8b-b64d-43a4-957b-4f662fc599cb:3359f4952ea2579f32fcf6c953072c8e"
)

# Moonshot APIé…ç½®
MOONSHOT_API_KEY = os.environ.get(
    "MOONSHOT_API_KEY",
    "sk-EZhdBSl7i7qn4N3DZFlMbqAGSblpJKX6gxCaUjYSxqVBVRPAImM7"
)
MOONSHOT_BASE_URL = "https://api.moonshot.cn/v1"
MOONSHOT_MODEL = "moonshot-v1-8k"

# æ¨¡å‹ç«¯ç‚¹
MODELS = {
    "kling": "fal-ai/kling-image/v3/text-to-image",
    "glm": "fal-ai/glm-image",
    "grok": "xai/grok-imagine-image",
}

# é£æ ¼é¢„è®¾ - é’ˆå¯¹ä¸åŒé£æ ¼ä¼˜åŒ–çš„åŸºç¡€æè¿°
STYLE_BASE = {
    "crypto": (
        "futuristic, neon accents, dark background with electric blue and purple gradients, "
        "blockchain aesthetic, high-tech visualization, professional social media graphic, 4K quality"
    ),
    "minimal": (
        "pure white background, simple geometric shapes, elegant typography space, "
        "subtle shadows, Scandinavian design aesthetic, plenty of white space, modern and professional"
    ),
    "news": (
        "editorial layout, bold headlines space, information graphic aesthetic, "
        "professional news media style, blue and white color scheme, trustworthy and authoritative look"
    ),
}


def get_moonshot_client() -> OpenAI:
    """åˆ›å»ºMoonshotå®¢æˆ·ç«¯"""
    return OpenAI(
        api_key=MOONSHOT_API_KEY,
        base_url=MOONSHOT_BASE_URL,
    )


def refine_prompt_with_llm(raw_content: str, style: str = "crypto") -> str:
    """
    ä½¿ç”¨Moonshot LLMå°†åŸå§‹æ¨æ–‡/æ®µè½å†…å®¹æç‚¼æˆé€‚åˆå›¾åƒç”Ÿæˆçš„è‹±æ–‡prompt
    
    Args:
        raw_content: åŸå§‹æ–‡æœ¬å†…å®¹
        style: å›¾ç‰‡é£æ ¼
        
    Returns:
        str: æç‚¼åçš„è‹±æ–‡image prompt
    """
    client = get_moonshot_client()
    
    # è·å–é£æ ¼æè¿°
    style_desc = STYLE_BASE.get(style, STYLE_BASE["crypto"])
    
    # æ„å»ºLLM prompt
    system_prompt = """You are an expert at converting text content into high-quality image generation prompts.
Your task is to transform the given content into 1-2 sentences of English description that:
1. Captures the key visual elements and mood of the content
2. Is optimized for AI image generation models
3. Focuses on visual composition, lighting, and atmosphere
4. Avoids text-heavy or typography-focused descriptions (as AI struggles with text)

Output ONLY the image prompt, nothing else."""
    
    user_prompt = f"""Convert the following content into an image generation prompt:

Content: {raw_content!r}

Style reference: {style_desc}

Generate a concise English image prompt:"""
    
    try:
        response = client.chat.completions.create(
            model=MOONSHOT_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.7,
            max_tokens=200,
        )
        
        refined = response.choices[0].message.content.strip()
        # ç§»é™¤å¯èƒ½çš„å¼•å·
        refined = refined.strip('"\'')
        return refined
    except Exception as e:
        print(f"   âš ï¸ LLMæç‚¼å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹: {e}")
        # Fallbackï¼šç›´æ¥ä½¿ç”¨åŸå§‹å†…å®¹
        return f"Illustration of: {raw_content[:200]}"


def split_content_into_segments(content: str) -> List[str]:
    """
    å°†é•¿æ–‡æœ¬æ‹†åˆ†ä¸ºå¤šä¸ªæ®µè½/ç‰‡æ®µ
    
    æ”¯æŒçš„åˆ†éš”ç¬¦ï¼š
    - åŒæ¢è¡Œï¼ˆæ®µè½ï¼‰
    - å•æ¢è¡Œï¼ˆçŸ­æ®µè½ï¼‰
    - ä¸­æ–‡å¥å·+æ¢è¡Œ
    
    Args:
        content: åŸå§‹æ–‡æœ¬å†…å®¹
        
    Returns:
        List[str]: æ–‡æœ¬ç‰‡æ®µåˆ—è¡¨
    """
    # é¦–å…ˆå°è¯•åŒæ¢è¡Œåˆ†éš”ï¼ˆæ®µè½ï¼‰
    segments = [s.strip() for s in content.split('\n\n') if s.strip()]
    
    # å¦‚æœæ®µè½å¤ªå°‘ï¼Œå°è¯•å•æ¢è¡Œ
    if len(segments) < 2:
        segments = [s.strip() for s in content.split('\n') if s.strip()]
    
    # è¿‡æ»¤æ‰å¤ªçŸ­çš„ç‰‡æ®µï¼ˆå°‘äº10ä¸ªå­—ç¬¦ï¼‰
    segments = [s for s in segments if len(s) >= 10]
    
    return segments


def generate_with_model(
    model_id: str,
    prompt: str,
    image_size: str = "square_hd"
) -> dict:
    """
    ä½¿ç”¨æŒ‡å®šæ¨¡å‹ç”Ÿæˆå›¾åƒ
    
    Args:
        model_id: æ¨¡å‹ç«¯ç‚¹ID
        prompt: å›¾åƒç”Ÿæˆæç¤ºè¯
        image_size: å›¾åƒå°ºå¯¸
        
    Returns:
        dict: åŒ…å« images çš„å“åº”æ•°æ®
    """
    os.environ["FAL_KEY"] = FAL_KEY
    
    result = fal_client.run(
        model_id,
        arguments={
            "prompt": prompt,
            "image_size": image_size,
        },
    )
    return result


def generate_single_image(
    prompt: str,
    output_path: str,
) -> dict:
    """
    ç”Ÿæˆå•å¼ å›¾ç‰‡
    
    Args:
        prompt: å›¾åƒç”Ÿæˆæç¤ºè¯
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
    Returns:
        dict: ç”Ÿæˆç»“æœ
    """
    print(f"ğŸš€ ä½¿ç”¨ Kling v3 ç”Ÿæˆä¸­...")
    print(f"   ğŸ“ Prompt: {prompt[:100]}...")
    
    try:
        start = time.time()
        result = generate_with_model(MODELS["kling"], prompt)
        elapsed = time.time() - start
        
        images = result.get("images", [])
        if images:
            url = images[0]["url"]
            urllib.request.urlretrieve(url, output_path)
            return {
                "url": url,
                "local": output_path,
                "time": elapsed,
                "success": True,
            }
        else:
            return {"error": "æ— å›¾åƒè¿”å›", "success": False}
    except Exception as e:
        return {"error": str(e), "success": False}


def generate_tweet_images_single(
    tweet: str,
    style: str = "crypto",
    output_path: str = "./output.png",
    use_llm: bool = True,
) -> dict:
    """
    å•æ¨æ–‡æ¨¡å¼ï¼šä¸ºå•æ¡æ¨æ–‡ç”Ÿæˆä¸€å¼ é…å›¾
    
    Args:
        tweet: æ¨æ–‡å†…å®¹
        style: å›¾ç‰‡é£æ ¼
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        use_llm: æ˜¯å¦ä½¿ç”¨LLMæç‚¼prompt
        
    Returns:
        dict: ç”Ÿæˆç»“æœ
    """
    print(f"ğŸ“ æ¨æ–‡å†…å®¹: {tweet[:50]}{'...' if len(tweet) > 50 else ''}")
    print(f"ğŸ¨ é£æ ¼: {style}")
    print()
    
    # ä½¿ç”¨LLMæç‚¼prompt
    if use_llm:
        print("ğŸ¤– ä½¿ç”¨Moonshot LLMæç‚¼Image Prompt...")
        refined_prompt = refine_prompt_with_llm(tweet, style)
        print(f"   âœ… æç‚¼å®Œæˆ: {refined_prompt[:80]}...")
        print()
        
        # ç»„åˆæœ€ç»ˆpromptï¼ˆé£æ ¼+æç‚¼å†…å®¹ï¼‰
        final_prompt = f"{refined_prompt}, {STYLE_BASE[style]}"
    else:
        final_prompt = f"Create an image for social media: {tweet}, {STYLE_BASE[style]}"
    
    result = generate_single_image(final_prompt, output_path)
    
    if result.get("success"):
        print(f"   âœ… æˆåŠŸ ({result['time']:.1f}s) â†’ {output_path}")
        return {
            "url": result["url"],
            "local": output_path,
            "time": result["time"],
            "prompt": final_prompt,
        }
    else:
        print(f"   âŒ å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        raise Exception(result.get("error", "ç”Ÿæˆå¤±è´¥"))


def generate_tweet_images_thread(
    content: str,
    style: str = "crypto",
    output_prefix: str = "./output",
) -> List[dict]:
    """
    Threadæ¨¡å¼ï¼šä¸ºå¤šæ®µè½å†…å®¹ç”Ÿæˆå¤šå¼ é…å›¾
    
    Args:
        content: å®Œæ•´æ–‡ç« å†…å®¹
        style: å›¾ç‰‡é£æ ¼
        output_prefix: è¾“å‡ºæ–‡ä»¶è·¯å¾„å‰ç¼€
        
    Returns:
        List[dict]: æ¯å¼ å›¾çš„ç”Ÿæˆç»“æœ
    """
    # æ‹†åˆ†æ®µè½
    segments = split_content_into_segments(content)
    
    if not segments:
        raise ValueError("æœªèƒ½ä»å†…å®¹ä¸­æå–æœ‰æ•ˆæ®µè½")
    
    print(f"ğŸ“„ å…±è¯†åˆ« {len(segments)} ä¸ªæ®µè½")
    print()
    
    results = []
    
    for i, segment in enumerate(segments, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ“Œ æ®µè½ {i}/{len(segments)}")
        print(f"{'='*60}")
        print(f"ğŸ“ å†…å®¹: {segment[:60]}{'...' if len(segment) > 60 else ''}")
        print()
        
        # ä½¿ç”¨LLMæç‚¼prompt
        print("ğŸ¤– ä½¿ç”¨Moonshot LLMæç‚¼Image Prompt...")
        refined_prompt = refine_prompt_with_llm(segment, style)
        print(f"   âœ… æç‚¼å®Œæˆ: {refined_prompt[:80]}...")
        print()
        
        # ç»„åˆæœ€ç»ˆprompt
        final_prompt = f"{refined_prompt}, {STYLE_BASE[style]}"
        
        # ç”Ÿæˆè¾“å‡ºè·¯å¾„
        if output_prefix.endswith('.png'):
            output_path = output_prefix.replace('.png', f'-{i}.png')
        else:
            output_path = f"{output_prefix}-{i}.png"
        
        # ç”Ÿæˆå›¾ç‰‡
        result = generate_single_image(final_prompt, output_path)
        
        if result.get("success"):
            print(f"   âœ… æˆåŠŸ ({result['time']:.1f}s) â†’ {output_path}")
            results.append({
                "segment_index": i,
                "segment_text": segment[:100],
                "prompt": refined_prompt,
                "url": result["url"],
                "local": output_path,
                "time": result["time"],
                "success": True,
            })
        else:
            print(f"   âŒ å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            results.append({
                "segment_index": i,
                "segment_text": segment[:100],
                "error": result.get('error', 'æœªçŸ¥é”™è¯¯'),
                "success": False,
            })
    
    return results


def main():
    """CLIå…¥å£"""
    parser = argparse.ArgumentParser(
        description="ä¸ºæ¨æ–‡ç”Ÿæˆé…å›¾",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å•æ¨æ–‡æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
  python run.py --tweet "æ¯”ç‰¹å¸æ–°é«˜ï¼ğŸš€" --style crypto
  python run.py --tweet "äº§å“å‘å¸ƒ" --style minimal --output ./product.png
  
  # Thread/æ–‡ç« å¤šå›¾æ¨¡å¼
  python run.py --mode thread --tweet "ç¬¬ä¸€æ®µå†…å®¹\n\nç¬¬äºŒæ®µå†…å®¹\n\nç¬¬ä¸‰æ®µå†…å®¹"
  python run.py --mode thread --tweet-file ./article.txt --style news --output ./article.png
  
  # è·³è¿‡LLMæç‚¼ï¼ˆä½¿ç”¨åŸå§‹å†…å®¹ç”Ÿæˆï¼‰
  python run.py --tweet "ç®€å•æµ‹è¯•" --no-llm
        """
    )
    parser.add_argument(
        "--tweet", "--content", "-t",
        dest="tweet",
        help="æ¨æ–‡/æ–‡ç« å†…å®¹ (--content ä¸º --tweet çš„åˆ«å)"
    )
    parser.add_argument(
        "--tweet-file", "-f",
        help="ä»æ–‡ä»¶è¯»å–æ¨æ–‡å†…å®¹"
    )
    parser.add_argument(
        "--mode", "-m",
        choices=["single", "thread"],
        default="single",
        help="ç”Ÿæˆæ¨¡å¼: single(å•å›¾) æˆ– thread(å¤šå›¾)ï¼Œé»˜è®¤: single"
    )
    parser.add_argument(
        "--style", "-s",
        choices=["crypto", "minimal", "news"],
        default="crypto",
        help="å›¾ç‰‡é£æ ¼ (é»˜è®¤: crypto)"
    )
    parser.add_argument(
        "--output", "-o",
        default="./output.png",
        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: ./output.pngï¼Œthreadæ¨¡å¼ä¸‹è‡ªåŠ¨æ·»åŠ åºå·)"
    )
    parser.add_argument(
        "--no-llm",
        action="store_true",
        help="ä¸ä½¿ç”¨LLMæç‚¼promptï¼ˆç›´æ¥ç”Ÿæˆï¼‰"
    )
    
    args = parser.parse_args()
    
    # éªŒè¯è¾“å…¥
    if not args.tweet and not args.tweet_file:
        parser.error("è¯·æä¾› --tweet æˆ– --tweet-file å‚æ•°")
    
    # è¯»å–å†…å®¹
    if args.tweet_file:
        with open(args.tweet_file, 'r', encoding='utf-8') as f:
            content = f.read()
    else:
        content = args.tweet
    
    print("=" * 60)
    print("TweetImageGen â€” æ¨æ–‡é…å›¾ç”Ÿæˆå™¨")
    print(f"æ¨¡å¼: {args.mode} | é£æ ¼: {args.style}")
    print("=" * 60)
    print()
    
    try:
        if args.mode == "single":
            # å•å›¾æ¨¡å¼
            result = generate_tweet_images_single(
                tweet=content,
                style=args.style,
                output_path=args.output,
                use_llm=not args.no_llm,
            )
            
            print("\n" + "=" * 60)
            print("ç”Ÿæˆç»“æœ")
            print("=" * 60)
            print(f"\nğŸ“· å›¾ç‰‡URL: {result['url']}")
            print(f"ğŸ’¾ æœ¬åœ°è·¯å¾„: {result['local']}")
            print(f"â±ï¸  è€—æ—¶: {result['time']:.1f}s")
            print(f"ğŸ“ ä½¿ç”¨Prompt: {result['prompt'][:100]}...")
            
        else:
            # Threadå¤šå›¾æ¨¡å¼
            results = generate_tweet_images_thread(
                content=content,
                style=args.style,
                output_prefix=args.output,
            )
            
            print("\n" + "=" * 60)
            print("ç”Ÿæˆç»“æœæ±‡æ€»")
            print("=" * 60)
            
            success_count = sum(1 for r in results if r.get("success"))
            print(f"\nâœ… æˆåŠŸ: {success_count}/{len(results)}")
            
            for r in results:
                if r.get("success"):
                    print(f"\nğŸ“· æ®µè½ {r['segment_index']}:")
                    print(f"   å†…å®¹: {r['segment_text'][:50]}...")
                    print(f"   URL: {r['url']}")
                    print(f"   æœ¬åœ°: {r['local']}")
                    print(f"   è€—æ—¶: {r['time']:.1f}s")
                else:
                    print(f"\nâŒ æ®µè½ {r['segment_index']}: {r.get('error', 'å¤±è´¥')}")
        
        return 0
        
    except ValueError as e:
        print(f"\nâŒ å‚æ•°é”™è¯¯: {e}")
        return 1
    except Exception as e:
        print(f"\nâŒ ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
