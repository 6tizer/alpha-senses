#!/usr/bin/env python3
"""
AudioAnalyzer â€” éŸ³é¢‘åˆ†æ Skill
ä½¿ç”¨ fal-ai/personaplex è¿›è¡Œè¯­éŸ³è½¬æ–‡å­—ã€æƒ…ç»ªåˆ†æå’Œå†…å®¹æ‘˜è¦

ç”¨æ³•:
    python run.py --audio <éŸ³é¢‘è·¯å¾„æˆ–URL> [--lang auto] [--output ./transcript.md] [--emotion]
    python run.py --audio ./recording.mp3 --lang zh --emotion

æ”¯æŒæ ¼å¼: mp3, wav, m4a, ogg, flac
"""
import argparse
import os
import sys
import time
import urllib.request
from typing import Optional

import fal_client

# FAL API Key
FAL_KEY = os.environ.get("FAL_KEY", "")


def upload_audio_if_needed(audio_path: str) -> str:
    """
    å¦‚æœæ˜¯æœ¬åœ°æ–‡ä»¶ï¼Œä¸Šä¼ åˆ° FAL è·å– URL
    
    Args:
        audio_path: éŸ³é¢‘è·¯å¾„æˆ– URL
        
    Returns:
        str: å¯è®¿é—®çš„ URL
    """
    if audio_path.startswith("http://") or audio_path.startswith("https://"):
        return audio_path
    
    print(f"ğŸ“¤ ä¸Šä¼ æœ¬åœ°éŸ³é¢‘: {audio_path}")
    url = fal_client.upload_file(audio_path)
    print(f"   âœ… ä¸Šä¼ å®Œæˆ")
    return url


def analyze_audio(
    audio_path: str,
    lang: str = "auto",
    emotion: bool = True,
) -> dict:
    """
    ä½¿ç”¨ fal-ai/personaplex åˆ†æéŸ³é¢‘
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„æˆ– URL
        lang: è¯­è¨€ (zh/en/autoï¼Œé»˜è®¤ auto)
        emotion: æ˜¯å¦è¿›è¡Œæƒ…ç»ªåˆ†æ
        
    Returns:
        dict: åˆ†æç»“æœåŒ…å« transcript, emotion, summary
    """
    if not FAL_KEY:
        raise ValueError("æœªè®¾ç½® FAL_KEY ç¯å¢ƒå˜é‡")
    
    os.environ["FAL_KEY"] = FAL_KEY
    
    # ä¸Šä¼ æœ¬åœ°æ–‡ä»¶
    audio_url = upload_audio_if_needed(audio_path)
    
    # æ„å»ºå‚æ•°
    arguments = {
        "audio_url": audio_url,
    }
    
    if lang != "auto":
        arguments["language"] = lang
    
    print(f"ğŸ™ï¸  æ­£åœ¨åˆ†æéŸ³é¢‘...")
    print(f"ğŸŒ è¯­è¨€: {lang}")
    print(f"ğŸ˜Š æƒ…ç»ªåˆ†æ: {'å¼€å¯' if emotion else 'å…³é—­'}")
    print()
    
    try:
        start = time.time()
        result = fal_client.run(
            "fal-ai/personaplex",
            arguments=arguments,
        )
        elapsed = time.time() - start
        
        # è§£æç»“æœ
        transcript = ""
        segments = []
        
        if isinstance(result, dict):
            # å°è¯•ä¸åŒå¯èƒ½çš„è¿”å›æ ¼å¼
            transcript = result.get("text", "")
            if not transcript:
                transcript = result.get("transcript", "")
            
            segments = result.get("segments", [])
            if not segments and "chunks" in result:
                segments = result.get("chunks", [])
        
        # å¦‚æœæ²¡æœ‰è·å¾—æ–‡æœ¬ï¼Œå°è¯•å…¶ä»–æ–¹å¼
        if not transcript and segments:
            transcript = " ".join([s.get("text", "") for s in segments])
        
        # æƒ…ç»ªåˆ†æï¼ˆå¦‚æœå¼€å¯ä¸”æ²¡æœ‰ç›´æ¥è¿”å›ï¼‰
        emotion_result = None
        if emotion:
            emotion_result = analyze_emotion(transcript) if transcript else None
        
        return {
            "transcript": transcript,
            "segments": segments,
            "emotion": emotion_result,
            "raw": result,
            "time": elapsed,
            "success": True,
        }
        
    except Exception as e:
        return {
            "error": str(e),
            "success": False,
        }


def analyze_emotion(transcript: str) -> dict:
    """
    å¯¹è½¬å½•æ–‡æœ¬è¿›è¡Œæƒ…ç»ªåˆ†æ
    
    Args:
        transcript: è½¬å½•æ–‡æœ¬
        
    Returns:
        dict: æƒ…ç»ªåˆ†æç»“æœ
    """
    # ç®€å•çš„å…³é”®è¯æƒ…ç»ªåˆ†æ
    # å®é™…ç”Ÿäº§ç¯å¢ƒå¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„ NLP æ¨¡å‹
    
    emotion_keywords = {
        "positive": ["å¥½", "æ£’", "ä¼˜ç§€", "å¼€å¿ƒ", "å–œæ¬¢", "æ„Ÿè°¢", "èµ", "å®Œç¾", "good", "great", "excellent", "happy", "love", "thanks", "amazing"],
        "negative": ["å·®", "ç³Ÿ", "è®¨åŒ", "å¤±æœ›", "éš¾è¿‡", "å", "é—®é¢˜", "é”™è¯¯", "bad", "terrible", "hate", "disappointed", "sad", "wrong", "error"],
        "excited": ["æ¿€åŠ¨", "å…´å¥‹", "å¤ªæ£’äº†", "å“‡", "å¤©å“ª", "excited", "wow", "amazing", "incredible"],
        "calm": ["å¹³é™", "æ”¾æ¾", "å®‰é™", "èˆ’é€‚", "calm", "relax", "peaceful", "comfortable"],
    }
    
    transcript_lower = transcript.lower()
    
    scores = {}
    for emotion, keywords in emotion_keywords.items():
        score = sum(1 for kw in keywords if kw in transcript_lower)
        scores[emotion] = score
    
    # æ‰¾å‡ºä¸»è¦æƒ…ç»ª
    total = sum(scores.values())
    if total > 0:
        dominant = max(scores, key=scores.get)
        percentages = {k: round(v / total * 100, 1) for k, v in scores.items()}
    else:
        dominant = "neutral"
        percentages = {k: 0 for k in emotion_keywords.keys()}
        percentages["neutral"] = 100
    
    return {
        "dominant": dominant,
        "percentages": percentages,
        "scores": scores,
    }


def summarize_transcript(transcript: str, lang: str = "zh") -> str:
    """
    ç”Ÿæˆå†…å®¹æ‘˜è¦
    
    Args:
        transcript: è½¬å½•æ–‡æœ¬
        lang: è¯­è¨€
        
    Returns:
        str: æ‘˜è¦
    """
    # ç®€å•çš„æ‘˜è¦ç”Ÿæˆ
    # å®é™…ç”Ÿäº§ç¯å¢ƒå¯ä»¥ä½¿ç”¨ LLM
    
    sentences = transcript.split("ã€‚") if lang == "zh" else transcript.split(".")
    sentences = [s.strip() for s in sentences if s.strip()]
    
    if len(sentences) <= 3:
        return transcript
    
    # å–å‰å‡ å¥ä½œä¸ºæ‘˜è¦
    summary_count = min(3, len(sentences) // 3 + 1)
    if lang == "zh":
        summary = "ã€‚".join(sentences[:summary_count]) + "ã€‚"
    else:
        summary = ". ".join(sentences[:summary_count]) + "."
    
    return summary


def format_output(result: dict, emotion: bool = True) -> str:
    """
    æ ¼å¼åŒ–è¾“å‡ºç»“æœ
    
    Args:
        result: åˆ†æç»“æœ
        emotion: æ˜¯å¦åŒ…å«æƒ…ç»ªåˆ†æ
        
    Returns:
        str: æ ¼å¼åŒ–çš„ Markdown æ–‡æœ¬
    """
    lines = []
    
    # å®Œæ•´è½¬å½•
    lines.append("# éŸ³é¢‘åˆ†ææŠ¥å‘Š")
    lines.append("")
    lines.append("## å®Œæ•´è½¬å½•")
    lines.append("")
    lines.append("```")
    lines.append(result.get("transcript", "N/A"))
    lines.append("```")
    lines.append("")
    
    # å†…å®¹æ‘˜è¦
    transcript = result.get("transcript", "")
    if transcript:
        summary = summarize_transcript(transcript)
        lines.append("## å†…å®¹æ‘˜è¦")
        lines.append("")
        lines.append(summary)
        lines.append("")
    
    # æƒ…ç»ªåˆ†æ
    if emotion and result.get("emotion"):
        emotion_data = result["emotion"]
        lines.append("## æƒ…ç»ªåˆ†æ")
        lines.append("")
        lines.append(f"**ä¸»è¦æƒ…ç»ª**: {emotion_data.get('dominant', 'neutral')}")
        lines.append("")
        lines.append("**æƒ…ç»ªåˆ†å¸ƒ**:")
        for emotion_type, percentage in emotion_data.get("percentages", {}).items():
            lines.append(f"- {emotion_type}: {percentage}%")
        lines.append("")
    
    # æ—¶é—´çº¿
    segments = result.get("segments", [])
    if segments:
        lines.append("## æ—¶é—´çº¿")
        lines.append("")
        for seg in segments[:20]:  # æœ€å¤šæ˜¾ç¤º20æ®µ
            start = seg.get("start", 0)
            end = seg.get("end", 0)
            text = seg.get("text", "")
            
            # æ ¼å¼åŒ–æ—¶é—´
            start_str = f"{int(start // 60):02d}:{int(start % 60):02d}"
            end_str = f"{int(end // 60):02d}:{int(end % 60):02d}"
            
            lines.append(f"**[{start_str} - {end_str}]** {text}")
        lines.append("")
    
    return "\n".join(lines)


def main():
    """CLIå…¥å£"""
    parser = argparse.ArgumentParser(
        description="éŸ³é¢‘åˆ†æå™¨ (Powered by fal-ai/personaplex)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºç¡€ä½¿ç”¨ï¼ˆè‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼‰
  python run.py --audio ./recording.mp3
  
  # æŒ‡å®šä¸­æ–‡ï¼Œå¼€å¯æƒ…ç»ªåˆ†æ
  python run.py --audio ./meeting.wav --lang zh --emotion
  
  # åˆ†æåœ¨çº¿éŸ³é¢‘
  python run.py --audio "https://example.com/audio.mp3" --output ./report.md
  
  # ä»…è½¬å½•ï¼Œä¸è¾“å‡ºæƒ…ç»ªåˆ†æ
  python run.py --audio ./podcast.mp3 --no-emotion
        """
    )
    parser.add_argument(
        "--audio", "-a",
        required=True,
        help="éŸ³é¢‘æ–‡ä»¶è·¯å¾„æˆ– URLï¼ˆå¿…å¡«ï¼Œæ”¯æŒ mp3/wav/m4a/ogg/flacï¼‰"
    )
    parser.add_argument(
        "--lang", "-l",
        choices=["zh", "en", "auto"],
        default="auto",
        help="è¯­è¨€ (é»˜è®¤: auto è‡ªåŠ¨æ£€æµ‹)"
    )
    parser.add_argument(
        "--output", "-o",
        default="./transcript.md",
        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: ./transcript.md)"
    )
    parser.add_argument(
        "--emotion", "-e",
        action="store_true",
        default=True,
        help="è¾“å‡ºæƒ…ç»ªåˆ†æ (é»˜è®¤å¼€å¯)"
    )
    parser.add_argument(
        "--no-emotion",
        action="store_true",
        help="å…³é—­æƒ…ç»ªåˆ†æ"
    )
    
    args = parser.parse_args()
    
    # å¤„ç† --no-emotion
    emotion = not args.no_emotion
    
    print("=" * 60)
    print("AudioAnalyzer â€” éŸ³é¢‘åˆ†æ")
    print("Powered by fal-ai/personaplex")
    print("=" * 60)
    print()
    
    try:
        result = analyze_audio(
            audio_path=args.audio,
            lang=args.lang,
            emotion=emotion,
        )
        
        if not result.get("success"):
            raise Exception(result.get("error", "åˆ†æå¤±è´¥"))
        
        # æ ¼å¼åŒ–è¾“å‡º
        output_content = format_output(result, emotion)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(args.output, "w", encoding="utf-8") as f:
            f.write(output_content)
        
        print("=" * 60)
        print("åˆ†æå®Œæˆ")
        print("=" * 60)
        print(f"\nâœ… åˆ†æè€—æ—¶: {result['time']:.1f}s")
        print(f"ğŸ“ è½¬å½•å­—æ•°: {len(result.get('transcript', ''))}")
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {args.output}")
        
        # æ‰“å°è½¬å½•é¢„è§ˆ
        transcript = result.get("transcript", "")
        if transcript:
            print(f"\nğŸ“„ è½¬å½•é¢„è§ˆ:")
            print("-" * 60)
            preview = transcript[:300]
            print(preview + "..." if len(transcript) > 300 else preview)
        
        # æ‰“å°æƒ…ç»ªåˆ†æé¢„è§ˆ
        if emotion and result.get("emotion"):
            emotion_data = result["emotion"]
            print(f"\nğŸ˜Š ä¸»è¦æƒ…ç»ª: {emotion_data.get('dominant', 'neutral')}")
        
        return 0
        
    except ValueError as e:
        print(f"\nâŒ é…ç½®é”™è¯¯: {e}")
        return 1
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
