#!/usr/bin/env python3
"""
TextToSpeech â€” æ–‡å­—è½¬è¯­éŸ³
å°†æ–‡å­—è½¬æ¢ä¸ºè‡ªç„¶è¯­éŸ³éŸ³é¢‘æ–‡ä»¶ï¼ˆåŸºäºMiniMax Speech 2.8 HDï¼‰

ç”¨æ³•:
    python run.py --text "ä½ å¥½ä¸–ç•Œ" --voice sweet_lady --output ./output.mp3
    python run.py --text "é‡è¦å…¬å‘Š" --voice executive --speed 0.9 --emotion serious
    python run.py --text "æµ‹è¯•æ‰€æœ‰éŸ³è‰²" --test-all-voices

éŸ³è‰²é€‰é¡¹:
    # ä¸­æ–‡éŸ³è‰²
    sweet_lady    - ç”œç¾å¥³ç”Ÿ (æ¸©æŸ”å¯çˆ±)
    executive     - å•†åŠ¡ç”·å£° (ç¨³é‡ä¸“ä¸š)
    wise_woman    - çŸ¥æ€§å¥³å£° (æˆç†Ÿç¿æ™º)
    news_anchor   - æ–°é—»ä¸»æ’­ (ä¸­æ€§æ­£å¼)
    gentle_youth  - æ¸©æŸ”é’å¹´ (ç”·å£°)
    warm_girl     - æ¸©æš–å¥³ç”Ÿ (äº²åˆ‡è‡ªç„¶)
    
    # è‹±æ–‡éŸ³è‰²
    female_en     - è‹±æ–‡å¥³å£°
    male_en       - è‹±æ–‡ç”·å£°
"""
import argparse
import os
import sys
import time
import urllib.request
from typing import Optional, List, Dict
from dataclasses import dataclass

import fal_client

# FAL API Key
FAL_KEY = os.environ.get(
    "FAL_API_KEY",
    "6bfc9d8b-b64d-43a4-957b-4f662fc599cb:3359f4952ea2579f32fcf6c953072c8e"
)


@dataclass
class VoiceConfig:
    """éŸ³è‰²é…ç½®ç±»"""
    voice_id: str
    name: str
    description: str
    gender: str  # male/female/neutral
    language: str  # zh/en


# MiniMax Speech 2.8 HD å®Œæ•´ä¸­æ–‡éŸ³è‰²åˆ—è¡¨
# æ¥æº: https://platform.minimax.io/docs/faq/system-voice-id
VOICE_CONFIGS: Dict[str, VoiceConfig] = {
    # === ä¸­æ–‡éŸ³è‰² (Mandarin) ===
    "sweet_lady": VoiceConfig(
        voice_id="Chinese (Mandarin)_Sweet_Lady",
        name="ç”œç¾å¥³ç”Ÿ",
        description="æ¸©æŸ”å¯çˆ±çš„å¹´è½»å¥³å£°ï¼Œé€‚åˆæ—¥å¸¸å¯¹è¯ã€æ•…äº‹è®²è¿°",
        gender="female",
        language="zh",
    ),
    "executive": VoiceConfig(
        voice_id="Chinese (Mandarin)_Reliable_Executive",
        name="å•†åŠ¡ç”·å£°",
        description="ç¨³é‡ä¸“ä¸šçš„ç”·å£°ï¼Œé€‚åˆå•†åŠ¡æ’­æŠ¥ã€æ­£å¼åœºåˆ",
        gender="male",
        language="zh",
    ),
    "wise_woman": VoiceConfig(
        voice_id="Chinese (Mandarin)_Wise_Woman",
        name="çŸ¥æ€§å¥³å£°",
        description="æˆç†Ÿç¿æ™ºçš„å¥³å£°ï¼Œé€‚åˆçŸ¥è¯†åˆ†äº«ã€æ·±åº¦å†…å®¹",
        gender="female",
        language="zh",
    ),
    "news_anchor": VoiceConfig(
        voice_id="Chinese (Mandarin)_News_Anchor",
        name="æ–°é—»ä¸»æ’­",
        description="æ ‡å‡†ä¸­æ€§æ–°é—»æ’­æŠ¥å£°éŸ³ï¼Œé€‚åˆèµ„è®¯æ’­æŠ¥",
        gender="neutral",
        language="zh",
    ),
    "gentle_youth": VoiceConfig(
        voice_id="Chinese (Mandarin)_Gentle_Youth",
        name="æ¸©æŸ”é’å¹´",
        description="æ¸©æ–‡å°”é›…çš„å¹´è½»ç”·å£°ï¼Œé€‚åˆè½»æ¾å†…å®¹",
        gender="male",
        language="zh",
    ),
    "warm_girl": VoiceConfig(
        voice_id="Chinese (Mandarin)_Warm_Girl",
        name="æ¸©æš–å¥³ç”Ÿ",
        description="äº²åˆ‡è‡ªç„¶çš„å¥³å£°ï¼Œé€‚åˆæƒ…æ„Ÿç±»å†…å®¹",
        gender="female",
        language="zh",
    ),
    
    # === æ‰©å±•ä¸­æ–‡éŸ³è‰² ===
    "mature_woman": VoiceConfig(
        voice_id="Chinese (Mandarin)_Mature_Woman",
        name="æˆç†Ÿå¥³æ€§",
        description="å¯Œæœ‰éŸµå‘³çš„æˆç†Ÿå¥³å£°",
        gender="female",
        language="zh",
    ),
    "gentleman": VoiceConfig(
        voice_id="Chinese (Mandarin)_Gentleman",
        name="ç»…å£«ç”·å£°",
        description="ä¼˜é›…ç»…å£«é£æ ¼çš„ç”·å£°",
        gender="male",
        language="zh",
    ),
    "cute_spirit": VoiceConfig(
        voice_id="Chinese (Mandarin)_Cute_Spirit",
        name="å¯çˆ±ç²¾çµ",
        description="æ´»æ³¼å¯çˆ±çš„å°‘å¥³å£°éŸ³",
        gender="female",
        language="zh",
    ),
    
    # === è‹±æ–‡éŸ³è‰² ===
    "female_en": VoiceConfig(
        voice_id="female-english",
        name="è‹±æ–‡å¥³å£°",
        description="ä¸“ä¸šè‹±æ–‡å¥³å£°",
        gender="female",
        language="en",
    ),
    "male_en": VoiceConfig(
        voice_id="male-english",
        name="è‹±æ–‡ç”·å£°",
        description="ä¸“ä¸šè‹±æ–‡ç”·å£°",
        gender="male",
        language="en",
    ),
}

# æƒ…ç»ªé€‰é¡¹ï¼ˆMiniMax Speech 2.8 HDæ”¯æŒï¼‰
EMOTION_OPTIONS = {
    "neutral": None,  # é»˜è®¤ï¼Œä¸æŒ‡å®š
    "happy": "happy",
    "sad": "sad",
    "angry": "angry",
    "fearful": "fearful",
    "surprised": "surprised",
    "calm": "calm",
    "serious": "calm",  # calmå¯ç”¨äºä¸¥è‚ƒåœºåˆ
    "fluent": "fluent",
}

# æµ‹è¯•ç”¨çš„ä¸­æ–‡æ–‡æœ¬
TEST_TEXT = """
ä½ å¥½ï¼Œæˆ‘æ˜¯AIè¯­éŸ³åŠ©æ‰‹ã€‚ä»Šå¤©æˆ‘è¦æµ‹è¯•ä¸åŒçš„ä¸­æ–‡éŸ³è‰²æ•ˆæœã€‚
äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼ï¼Œè®©æŠ€æœ¯æ›´åŠ äººæ€§åŒ–ã€‚
æ„Ÿè°¢ä½ çš„è†å¬ï¼Œå¸Œæœ›è¿™æ¬¡æµ‹è¯•å¯¹ä½ æœ‰å¸®åŠ©ã€‚
""".strip()


def text_to_speech(
    text: str,
    voice_id: str,
    output_path: str = "./output.mp3",
    speed: float = 1.0,
    emotion: Optional[str] = None,
    verbose: bool = True,
) -> dict:
    """
    å°†æ–‡å­—è½¬æ¢ä¸ºè¯­éŸ³
    
    Args:
        text: è¦è½¬æ¢çš„æ–‡å­—å†…å®¹
        voice_id: MiniMaxåŸç”Ÿvoice ID
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        speed: è¯­é€Ÿï¼ŒèŒƒå›´0.5-2.0ï¼Œé»˜è®¤1.0
        emotion: æƒ…ç»ªé€‰é¡¹ (happy/sad/angry/fearful/surprised/calm/fluent)
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        
    Returns:
        dict: ç”Ÿæˆç»“æœï¼ŒåŒ…å« urlã€local è·¯å¾„å’Œ duration
    """
    # éªŒè¯å‚æ•°
    if not (0.5 <= speed <= 2.0):
        raise ValueError(f"è¯­é€Ÿå‚æ•°speedå¿…é¡»åœ¨0.5-2.0èŒƒå›´å†…ï¼Œå½“å‰: {speed}")
    
    if verbose:
        print(f"ğŸ“ æ–‡å­—å†…å®¹: {text[:50]}{'...' if len(text) > 50 else ''}")
        print(f"ğŸ”Š Voice ID: {voice_id}")
        print(f"âš¡ è¯­é€Ÿ: {speed}x")
        if emotion:
            print(f"ğŸ˜Š æƒ…ç»ª: {emotion}")
        print()
    
    os.environ["FAL_KEY"] = FAL_KEY
    
    # æ„å»ºAPIå‚æ•°
    arguments = {
        "prompt": text,
        "voice_id": voice_id,
        "speed": speed,
    }
    
    # æ·»åŠ æƒ…ç»ªå‚æ•°ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    if emotion and emotion in EMOTION_OPTIONS:
        emotion_value = EMOTION_OPTIONS[emotion]
        if emotion_value:
            arguments["emotion"] = emotion_value
    
    if verbose:
        print(f"ğŸš€ è°ƒç”¨ MiniMax Speech-2.8-HD ç”Ÿæˆä¸­...")
        print(f"   å‚æ•°: {arguments}")
    
    try:
        start = time.time()
        result = fal_client.run(
            "fal-ai/minimax/speech-2.8-hd",
            arguments=arguments,
        )
        elapsed = time.time() - start
        
        # è§£æç»“æœ
        audio_data = result.get("audio", {})
        audio_url = audio_data.get("url")
        duration_ms = result.get("duration_ms")
        duration = duration_ms / 1000 if duration_ms else None
        
        if audio_url:
            urllib.request.urlretrieve(audio_url, output_path)
            
            if verbose:
                print(f"   âœ… æˆåŠŸ ({elapsed:.1f}s)")
                print(f"   ğŸ’¾ å·²ä¿å­˜: {output_path}")
                if duration:
                    print(f"   â±ï¸  éŸ³é¢‘æ—¶é•¿: {duration:.1f}ç§’")
            
            return {
                "url": audio_url,
                "local": output_path,
                "time": elapsed,
                "duration": duration,
                "voice_id": voice_id,
                "speed": speed,
                "emotion": emotion,
                "success": True,
            }
        else:
            raise Exception(f"æ— éŸ³é¢‘è¿”å›: {result}")
            
    except Exception as e:
        if verbose:
            print(f"   âŒ å¤±è´¥: {e}")
        return {
            "error": str(e),
            "voice_id": voice_id,
            "success": False,
        }


def list_voices(language: Optional[str] = None) -> List[VoiceConfig]:
    """
    åˆ—å‡ºå¯ç”¨éŸ³è‰²
    
    Args:
        language: ç­›é€‰è¯­è¨€ ('zh'/'en')ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨
        
    Returns:
        List[VoiceConfig]: éŸ³è‰²é…ç½®åˆ—è¡¨
    """
    voices = list(VOICE_CONFIGS.values())
    if language:
        voices = [v for v in voices if v.language == language]
    return voices


def print_voice_list():
    """æ‰“å°å¯ç”¨éŸ³è‰²åˆ—è¡¨"""
    print("=" * 60)
    print("å¯ç”¨éŸ³è‰²åˆ—è¡¨")
    print("=" * 60)
    
    # ä¸­æ–‡éŸ³è‰²
    print("\nğŸ€„ ä¸­æ–‡éŸ³è‰²:")
    zh_voices = list_voices("zh")
    for key, config in VOICE_CONFIGS.items():
        if config.language == "zh":
            gender_emoji = "ğŸ‘©" if config.gender == "female" else "ğŸ‘¨" if config.gender == "male" else "ğŸ§‘"
            print(f"  {gender_emoji} {key:15} - {config.name:10} | {config.description}")
    
    # è‹±æ–‡éŸ³è‰²
    print("\nğŸ‡ºğŸ‡¸ è‹±æ–‡éŸ³è‰²:")
    for key, config in VOICE_CONFIGS.items():
        if config.language == "en":
            gender_emoji = "ğŸ‘©" if config.gender == "female" else "ğŸ‘¨"
            print(f"  {gender_emoji} {key:15} - {config.name:10} | {config.description}")


def test_all_voices(output_dir: str = "./voice_test"):
    """
    æµ‹è¯•æ‰€æœ‰ä¸­æ–‡éŸ³è‰²å¹¶ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    
    Args:
        output_dir: æµ‹è¯•éŸ³é¢‘è¾“å‡ºç›®å½•
    """
    import os
    os.makedirs(output_dir, exist_ok=True)
    
    print("=" * 60)
    print("ğŸ™ï¸  ä¸­æ–‡éŸ³è‰²å¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    print(f"\næµ‹è¯•æ–‡æœ¬:\n{TEST_TEXT}\n")
    print(f"è¾“å‡ºç›®å½•: {output_dir}\n")
    
    zh_voices = list_voices("zh")
    results = []
    
    for i, config in enumerate(zh_voices, 1):
        # æ‰¾åˆ°å¯¹åº”çš„key
        voice_key = None
        for k, v in VOICE_CONFIGS.items():
            if v.voice_id == config.voice_id:
                voice_key = k
                break
        
        output_path = os.path.join(output_dir, f"test_{voice_key}.mp3")
        
        print(f"\n{'='*60}")
        print(f"[{i}/{len(zh_voices)}] æµ‹è¯•éŸ³è‰²: {config.name}")
        print(f"Voice ID: {config.voice_id}")
        print(f"{'='*60}")
        
        result = text_to_speech(
            text=TEST_TEXT,
            voice_id=config.voice_id,
            output_path=output_path,
            speed=1.0,
            emotion=None,
            verbose=True,
        )
        
        results.append({
            "key": voice_key,
            "config": config,
            **result,
        })
    
    # è¾“å‡ºå¯¹æ¯”æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•æŠ¥å‘Šæ±‡æ€»")
    print("=" * 60)
    
    success_count = sum(1 for r in results if r.get("success"))
    print(f"\nâœ… æˆåŠŸ: {success_count}/{len(results)}")
    
    print("\n| åºå· | éŸ³è‰²Key | åç§° | æ€§åˆ« | æ—¶é•¿ | çŠ¶æ€ | æ–‡ä»¶è·¯å¾„ |")
    print("|------|---------|------|------|------|------|----------|")
    
    for i, r in enumerate(results, 1):
        config = r["config"]
        gender = "å¥³" if config.gender == "female" else "ç”·" if config.gender == "male" else "ä¸­"
        duration = f"{r['duration']:.1f}s" if r.get("duration") else "N/A"
        status = "âœ…" if r.get("success") else "âŒ"
        path = r.get("local", "N/A") if r.get("success") else r.get("error", "å¤±è´¥")
        
        print(f"| {i:2} | {r['key']:12} | {config.name:8} | {gender} | {duration:6} | {status} | {path} |")
    
    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
    report_path = os.path.join(output_dir, "report.md")
    with open(report_path, "w", encoding="utf-8") as f:
        f.write("# MiniMax Speech 2.8 HD ä¸­æ–‡éŸ³è‰²æµ‹è¯•æŠ¥å‘Š\n\n")
        f.write(f"æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"## æµ‹è¯•æ–‡æœ¬\n\n```\n{TEST_TEXT}\n```\n\n")
        f.write("## æµ‹è¯•ç»“æœ\n\n")
        f.write("| åºå· | éŸ³è‰²Key | åç§° | æ€§åˆ« | æè¿° | æ—¶é•¿ | çŠ¶æ€ |\n")
        f.write("|------|---------|------|------|------|------|------|\n")
        
        for i, r in enumerate(results, 1):
            config = r["config"]
            gender = "å¥³" if config.gender == "female" else "ç”·" if config.gender == "male" else "ä¸­"
            duration = f"{r['duration']:.1f}s" if r.get("duration") else "N/A"
            status = "âœ… æˆåŠŸ" if r.get("success") else f"âŒ å¤±è´¥: {r.get('error', 'æœªçŸ¥é”™è¯¯')}"
            
            f.write(f"| {i} | {r['key']} | {config.name} | {gender} | {config.description} | {duration} | {status} |\n")
        
        f.write("\n## æ¨èéŸ³è‰²\n\n")
        f.write("- **ç”œç¾å¥³å£°**: sweet_lady - é€‚åˆæ—¥å¸¸å¯¹è¯ã€æ•…äº‹è®²è¿°\n")
        f.write("- **å•†åŠ¡ç”·å£°**: executive - é€‚åˆæ­£å¼æ’­æŠ¥ã€å•†åŠ¡åœºæ™¯\n")
        f.write("- **çŸ¥æ€§å¥³å£°**: wise_woman - é€‚åˆçŸ¥è¯†åˆ†äº«ã€æ·±åº¦å†…å®¹\n")
        f.write("- **æ–°é—»ä¸»æ’­**: news_anchor - é€‚åˆæ–°é—»èµ„è®¯ã€æ ‡å‡†æ’­æŠ¥\n")
    
    print(f"\nğŸ“ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")


def main():
    """CLIå…¥å£"""
    parser = argparse.ArgumentParser(
        description="æ–‡å­—è½¬è¯­éŸ³ (MiniMax Speech 2.8 HD)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºç¡€ä½¿ç”¨
  python run.py --text "ä½ å¥½ï¼Œä¸–ç•Œï¼" --voice sweet_lady
  
  # è°ƒæ•´è¯­é€Ÿå’Œæƒ…ç»ª
  python run.py --text "é‡è¦é€šçŸ¥" --voice executive --speed 0.9 --emotion calm
  
  # å¿«é€Ÿè¯­é€Ÿ
  python run.py --text "å¿«é€Ÿæ’­æŠ¥" --voice news_anchor --speed 1.3
  
  # åˆ—å‡ºæ‰€æœ‰éŸ³è‰²
  python run.py --list-voices
  
  # æµ‹è¯•æ‰€æœ‰ä¸­æ–‡éŸ³è‰²å¹¶ç”ŸæˆæŠ¥å‘Š
  python run.py --test-all-voices --output-dir ./voice_test
        """
    )
    parser.add_argument(
        "--text", "-t",
        help="è¦è½¬æ¢çš„æ–‡å­—å†…å®¹"
    )
    parser.add_argument(
        "--voice", "-v",
        choices=list(VOICE_CONFIGS.keys()),
        default="sweet_lady",
        help="éŸ³è‰²é€‰é¡¹ (é»˜è®¤: sweet_lady)"
    )
    parser.add_argument(
        "--output", "-o",
        default="./output.mp3",
        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: ./output.mp3)"
    )
    parser.add_argument(
        "--speed", "-s",
        type=float,
        default=1.0,
        help="è¯­é€Ÿï¼ŒèŒƒå›´0.5-2.0 (é»˜è®¤: 1.0)"
    )
    parser.add_argument(
        "--emotion", "-e",
        choices=list(EMOTION_OPTIONS.keys()),
        default=None,
        help="æƒ…ç»ªé€‰é¡¹ (é»˜è®¤: neutral)"
    )
    parser.add_argument(
        "--list-voices",
        action="store_true",
        help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨éŸ³è‰²"
    )
    parser.add_argument(
        "--test-all-voices",
        action="store_true",
        help="æµ‹è¯•æ‰€æœ‰ä¸­æ–‡éŸ³è‰²å¹¶ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"
    )
    parser.add_argument(
        "--output-dir",
        default="./voice_test",
        help="æµ‹è¯•éŸ³é¢‘è¾“å‡ºç›®å½• (é»˜è®¤: ./voice_test)"
    )
    
    args = parser.parse_args()
    
    # åˆ—å‡ºéŸ³è‰²
    if args.list_voices:
        print_voice_list()
        return 0
    
    # æµ‹è¯•æ‰€æœ‰éŸ³è‰²
    if args.test_all_voices:
        test_all_voices(args.output_dir)
        return 0
    
    # éªŒè¯textå‚æ•°
    if not args.text:
        parser.error("è¯·æä¾› --text å‚æ•°ï¼ˆæˆ–ä½¿ç”¨ --list-voices / --test-all-voicesï¼‰")
    
    print("=" * 60)
    print("TextToSpeech â€” æ–‡å­—è½¬è¯­éŸ³")
    print("Powered by MiniMax Speech-2.8-HD")
    print("=" * 60)
    print()
    
    # è·å–éŸ³è‰²é…ç½®
    voice_config = VOICE_CONFIGS[args.voice]
    
    try:
        result = text_to_speech(
            text=args.text,
            voice_id=voice_config.voice_id,
            output_path=args.output,
            speed=args.speed,
            emotion=args.emotion,
            verbose=True,
        )
        
        if not result.get("success"):
            raise Exception(result.get("error", "æœªçŸ¥é”™è¯¯"))
        
        print("\n" + "=" * 60)
        print("ç”Ÿæˆç»“æœ")
        print("=" * 60)
        print(f"\nğŸ™ï¸  éŸ³è‰²: {voice_config.name} ({voice_config.description})")
        print(f"ğŸ”Š Voice ID: {voice_config.voice_id}")
        print(f"ğŸ”— URL: {result['url']}")
        print(f"ğŸ’¾ æœ¬åœ°: {result['local']}")
        print(f"âš¡ è¯­é€Ÿ: {result['speed']}x")
        if result.get('emotion'):
            print(f"ğŸ˜Š æƒ…ç»ª: {result['emotion']}")
        print(f"â±ï¸  è€—æ—¶: {result['time']:.1f}s")
        if result.get('duration'):
            print(f"ğŸµ éŸ³é¢‘æ—¶é•¿: {result['duration']:.1f}ç§’")
        
        return 0
        
    except ValueError as e:
        print(f"\nâŒ å‚æ•°é”™è¯¯: {e}")
        return 1
    except Exception as e:
        print(f"\nâŒ ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
